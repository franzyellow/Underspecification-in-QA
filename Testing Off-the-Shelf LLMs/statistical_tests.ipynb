{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "210a13b9-36d0-4e7b-9078-f94fbf4ef42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "import pandas as pd\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db23c378-dcc9-4a84-8a8f-c48838e560e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_chi_square_test(df, subset_col, gold_col, pred_col, subset_names=None):\n",
    "    \"\"\"\n",
    "    对不同子集上的 accuracy 做卡方检验，判断是否显著不同。\n",
    "\n",
    "    参数：\n",
    "    - df: 包含预测结果的 DataFrame\n",
    "    - subset_col: 区分子集的列名（如 'direct_source'）\n",
    "    - gold_col: 真实标签列名（如 'gold_judgment'）\n",
    "    - pred_col: 模型预测标签列名（如 'model_pred'）\n",
    "    - subset_names: 可选，指定要比较的子集名列表，默认是全部子集\n",
    "\n",
    "    返回：\n",
    "    - accuracy_table: 各子集的 [正确预测数, 错误预测数] 列表\n",
    "    - p_value: 卡方检验的 p 值\n",
    "    \"\"\"\n",
    "\n",
    "    if subset_names is None:\n",
    "        subset_names = df[subset_col].unique()\n",
    "\n",
    "    accuracy_table = []\n",
    "\n",
    "    for subset in subset_names:\n",
    "        sub_df = df[df[subset_col] == subset]\n",
    "        correct = (sub_df[gold_col] == sub_df[pred_col]).sum()\n",
    "        total = len(sub_df)\n",
    "        accuracy_table.append([correct, total - correct])\n",
    "\n",
    "    chi2, p, dof, expected = chi2_contingency(accuracy_table)\n",
    "\n",
    "    print(\"Contingency Table:\", accuracy_table)\n",
    "    print(f\"Chi-square stat = {chi2:.4f}, p-value = {p:.4f}\")\n",
    "    return accuracy_table, p\n",
    "\n",
    "def pairwise_accuracy_chi_square(df, subset_col, gold_col, pred_col, subset_names=None, alpha=0.05):\n",
    "    if subset_names is None:\n",
    "        subset_names = df[subset_col].unique()\n",
    "\n",
    "    results = []\n",
    "    comparisons = list(combinations(subset_names, 2))\n",
    "    corrected_alpha = alpha / len(comparisons)\n",
    "\n",
    "    for a, b in comparisons:\n",
    "        df_a = df[df[subset_col] == a]\n",
    "        df_b = df[df[subset_col] == b]\n",
    "\n",
    "        correct_a = (df_a[gold_col] == df_a[pred_col]).sum()\n",
    "        wrong_a = len(df_a) - correct_a\n",
    "        correct_b = (df_b[gold_col] == df_b[pred_col]).sum()\n",
    "        wrong_b = len(df_b) - correct_b\n",
    "\n",
    "        contingency_table = [[correct_a, wrong_a], [correct_b, wrong_b]]\n",
    "        chi2, p, dof, expected = chi2_contingency(contingency_table)\n",
    "\n",
    "        results.append({\n",
    "            'comparison': f\"{a} vs {b}\",\n",
    "            'accuracy_a': correct_a / len(df_a),\n",
    "            'accuracy_b': correct_b / len(df_b),\n",
    "            'p_value': p,\n",
    "            'significant': p < corrected_alpha\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a8c8873-68b5-4289-89b0-e8055b8b3491",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_macro_f1(y_true, y_pred, n_bootstrap=1000):\n",
    "    scores = []\n",
    "    n = len(y_true)\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    for _ in range(n_bootstrap):\n",
    "        idx = np.random.choice(n, n, replace=True)\n",
    "        f1 = f1_score(y_true[idx], y_pred[idx], average='macro')\n",
    "        scores.append(f1)\n",
    "    return np.percentile(scores, 2.5), np.percentile(scores, 97.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "42fba589-8ce6-4fa6-ac40-f80e6fde5cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed24d592-9062-4257-b799-84ea099d5e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing results for Qwen3_4B_FS_UND.csv:\n",
      "Contingency Table: [[126, 30], [219, 80], [258, 142]]\n",
      "Chi-square stat = 15.9247, p-value = 0.0003\n",
      "\n",
      "           comparison  accuracy_a  accuracy_b   p_value  significant\n",
      "0      CoCoNot vs IN3    0.807692    0.732441  0.096072        False\n",
      "1  CoCoNot vs CLAMBER    0.807692    0.645000  0.000287         True\n",
      "2      IN3 vs CLAMBER    0.732441    0.645000  0.017559        False\n",
      "\n",
      "CoCoNot Macro-F1 95% CI: [0.7048, 0.8430]\n",
      "IN3 Macro-F1 95% CI: [0.6823, 0.7792]\n",
      "CLAMBER Macro-F1 95% CI: [0.5944, 0.6874]\n",
      "-----------------------\n",
      "Printing results for Qwen3_32B_FS_UND.csv:\n",
      "Contingency Table: [[127, 29], [215, 84], [254, 146]]\n",
      "Chi-square stat = 18.1017, p-value = 0.0001\n",
      "\n",
      "           comparison  accuracy_a  accuracy_b   p_value  significant\n",
      "0      CoCoNot vs IN3    0.814103    0.719064  0.034612        False\n",
      "1  CoCoNot vs CLAMBER    0.814103    0.635000  0.000068         True\n",
      "2      IN3 vs CLAMBER    0.719064    0.635000  0.023890        False\n",
      "\n",
      "CoCoNot Macro-F1 95% CI: [0.7174, 0.8571]\n",
      "IN3 Macro-F1 95% CI: [0.6688, 0.7666]\n",
      "CLAMBER Macro-F1 95% CI: [0.5824, 0.6751]\n",
      "-----------------------\n",
      "Printing results for Qwen3_4B_UND_FS_DSPy_CoT_no_theory_examples_wording_A.csv:\n",
      "Contingency Table: [[121, 35], [200, 99], [243, 157]]\n",
      "Chi-square stat = 14.3076, p-value = 0.0008\n",
      "\n",
      "           comparison  accuracy_a  accuracy_b   p_value  significant\n",
      "0      CoCoNot vs IN3    0.775641    0.668896  0.023652        False\n",
      "1  CoCoNot vs CLAMBER    0.775641    0.607500  0.000265         True\n",
      "2      IN3 vs CLAMBER    0.668896    0.607500  0.112373        False\n",
      "\n",
      "CoCoNot Macro-F1 95% CI: [0.7026, 0.8362]\n",
      "IN3 Macro-F1 95% CI: [0.5771, 0.6914]\n",
      "CLAMBER Macro-F1 95% CI: [0.5290, 0.6275]\n",
      "-----------------------\n",
      "Printing results for Qwen3_4B_DSPy_FS_UND.csv:\n",
      "Contingency Table: [[131, 25], [210, 89], [259, 141]]\n",
      "Chi-square stat = 19.8185, p-value = 0.0000\n",
      "\n",
      "           comparison  accuracy_a  accuracy_b   p_value  significant\n",
      "0      CoCoNot vs IN3    0.839744    0.702341  0.001958         True\n",
      "1  CoCoNot vs CLAMBER    0.839744    0.647500  0.000014         True\n",
      "2      IN3 vs CLAMBER    0.702341    0.647500  0.148354        False\n",
      "\n",
      "CoCoNot Macro-F1 95% CI: [0.7632, 0.8838]\n",
      "IN3 Macro-F1 95% CI: [0.6475, 0.7502]\n",
      "CLAMBER Macro-F1 95% CI: [0.5888, 0.6843]\n",
      "-----------------------\n",
      "Printing results for DS14B_FS_UND_correct.csv:\n",
      "Contingency Table: [[122, 34], [194, 105], [264, 136]]\n",
      "Chi-square stat = 9.5005, p-value = 0.0086\n",
      "\n",
      "           comparison  accuracy_a  accuracy_b   p_value  significant\n",
      "0      CoCoNot vs IN3    0.782051    0.648829  0.004785         True\n",
      "1  CoCoNot vs CLAMBER    0.782051    0.660000  0.006851         True\n",
      "2      IN3 vs CLAMBER    0.648829    0.660000  0.820423        False\n",
      "\n",
      "CoCoNot Macro-F1 95% CI: [0.6638, 0.8178]\n",
      "IN3 Macro-F1 95% CI: [0.5808, 0.6938]\n",
      "CLAMBER Macro-F1 95% CI: [0.6020, 0.7014]\n",
      "-----------------------\n",
      "Printing results for DS_R1_API_FS_UND.csv:\n",
      "Contingency Table: [[126, 30], [223, 76], [262, 138]]\n",
      "Chi-square stat = 15.0252, p-value = 0.0005\n",
      "\n",
      "           comparison  accuracy_a  accuracy_b   p_value  significant\n",
      "0      CoCoNot vs IN3    0.807692    0.745819  0.172207        False\n",
      "1  CoCoNot vs CLAMBER    0.807692    0.655000  0.000626         True\n",
      "2      IN3 vs CLAMBER    0.745819    0.655000  0.012610         True\n",
      "\n",
      "CoCoNot Macro-F1 95% CI: [0.7056, 0.8455]\n",
      "IN3 Macro-F1 95% CI: [0.6943, 0.7862]\n",
      "CLAMBER Macro-F1 95% CI: [0.6091, 0.7019]\n",
      "-----------------------\n",
      "Printing results for DS_V3_FS_UND.csv:\n",
      "Contingency Table: [[132, 24], [220, 79], [254, 146]]\n",
      "Chi-square stat = 25.8675, p-value = 0.0000\n",
      "\n",
      "           comparison  accuracy_a  accuracy_b   p_value  significant\n",
      "0      CoCoNot vs IN3    0.846154    0.735786  0.010702         True\n",
      "1  CoCoNot vs CLAMBER    0.846154    0.635000  0.000002         True\n",
      "2      IN3 vs CLAMBER    0.735786    0.635000  0.006145         True\n",
      "\n",
      "CoCoNot Macro-F1 95% CI: [0.7669, 0.8859]\n",
      "IN3 Macro-F1 95% CI: [0.6638, 0.7703]\n",
      "CLAMBER Macro-F1 95% CI: [0.5711, 0.6682]\n",
      "-----------------------\n",
      "Printing results for llama_3_3_70B_FS_UND.csv:\n",
      "Contingency Table: [[128, 28], [234, 65], [246, 154]]\n",
      "Chi-square stat = 34.5152, p-value = 0.0000\n",
      "\n",
      "           comparison  accuracy_a  accuracy_b   p_value  significant\n",
      "0      CoCoNot vs IN3    0.820513    0.782609  0.406976        False\n",
      "1  CoCoNot vs CLAMBER    0.820513    0.615000  0.000006         True\n",
      "2      IN3 vs CLAMBER    0.782609    0.615000  0.000003         True\n",
      "\n",
      "CoCoNot Macro-F1 95% CI: [0.7374, 0.8716]\n",
      "IN3 Macro-F1 95% CI: [0.7077, 0.8107]\n",
      "CLAMBER Macro-F1 95% CI: [0.5250, 0.6285]\n",
      "-----------------------\n",
      "Printing results for Llama_70B_DSPy_CoT_FS_UND.csv:\n",
      "Contingency Table: [[117, 39], [221, 78], [258, 142]]\n",
      "Chi-square stat = 9.7107, p-value = 0.0078\n",
      "\n",
      "           comparison  accuracy_a  accuracy_b   p_value  significant\n",
      "0      CoCoNot vs IN3     0.75000     0.73913  0.889596        False\n",
      "1  CoCoNot vs CLAMBER     0.75000     0.64500  0.023015        False\n",
      "2      IN3 vs CLAMBER     0.73913     0.64500  0.010200         True\n",
      "\n",
      "CoCoNot Macro-F1 95% CI: [0.6522, 0.7969]\n",
      "IN3 Macro-F1 95% CI: [0.6873, 0.7869]\n",
      "CLAMBER Macro-F1 95% CI: [0.5910, 0.6854]\n",
      "-----------------------\n"
     ]
    }
   ],
   "source": [
    "result_files = ['Qwen3_4B_FS_UND.csv', 'Qwen3_32B_FS_UND.csv', 'Qwen3_4B_UND_FS_DSPy_CoT_no_theory_examples_wording_A.csv', \n",
    "                'Qwen3_4B_DSPy_FS_UND.csv', 'DS14B_FS_UND_correct.csv', 'DS_R1_API_FS_UND.csv', 'DS_V3_FS_UND.csv',\n",
    "                'llama_3_3_70B_FS_UND.csv', 'Llama_70B_DSPy_CoT_FS_UND.csv']\n",
    "\n",
    "for file_name in result_files:\n",
    "    df = pd.read_csv(file_name)\n",
    "    print(f'Printing results for {file_name}:')\n",
    "    \n",
    "    accuracy_chi_square_test(\n",
    "    df,\n",
    "    subset_col='direct_source',\n",
    "    gold_col='gold_judgment',\n",
    "    pred_col='model_pred',\n",
    "    subset_names=['CoCoNot', 'IN3', 'CLAMBER']\n",
    ")\n",
    "    print()\n",
    "    pairwise_df = pairwise_accuracy_chi_square(\n",
    "        df,\n",
    "        subset_col='direct_source',\n",
    "        gold_col='gold_judgment',\n",
    "        pred_col='model_pred',\n",
    "        subset_names=['CoCoNot', 'IN3', 'CLAMBER']\n",
    "    )\n",
    "    print(pairwise_df)  \n",
    "    print()\n",
    "    # 对每个子集计算 Bootstrap 置信区间\n",
    "    for subset in ['CoCoNot', 'IN3', 'CLAMBER']:\n",
    "        subset_df = df[df['direct_source'] == subset]\n",
    "        lower, upper = bootstrap_macro_f1(subset_df['gold_judgment'], subset_df['model_pred'])\n",
    "        print(f\"{subset} Macro-F1 95% CI: [{lower:.4f}, {upper:.4f}]\")\n",
    "\n",
    "    print(\"-----------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (sglang-venv-2)",
   "language": "python",
   "name": "sglang-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
